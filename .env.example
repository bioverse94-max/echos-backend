# ================================================
# Echoes Backend - Environment Configuration
# Optimized for OpenRouter API
# ================================================

# ------------------------------------------------
# Server Configuration
# ------------------------------------------------
PORT=8000
HOST=0.0.0.0
RELOAD=true

# ------------------------------------------------
# CORS Settings
# ------------------------------------------------
# Development: Use * or specify origins
# Production: MUST specify exact origins (comma-separated)
# Example: ALLOWED_ORIGINS=https://yourdomain.com,https://app.yourdomain.com
ALLOWED_ORIGINS=*

# ------------------------------------------------
# OpenRouter API Configuration
# ------------------------------------------------
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=<enter api key>

# Model selection (see https://openrouter.ai/models)
# Recommended models:
#   - qwen/qwen-2.5-72b-instruct (excellent & affordable)
#   - deepseek/deepseek-chat (very cheap)
#   - anthropic/claude-3.5-sonnet (highest quality, more expensive)
OPENROUTER_MODEL=qwen/qwen-2.5-72b-instruct

# Optional: Your app URL (for OpenRouter analytics)
OPENROUTER_SITE_URL=https://echoes-app.local
OPENROUTER_APP_NAME=Echoes-Backend

# ------------------------------------------------
# LLM Behavior Settings
# ------------------------------------------------
# Temperature: 0.0 (deterministic) to 1.0 (creative)
LLM_TEMPERATURE=0.7

# Max tokens per response
LLM_MAX_TOKENS=2000

# Timeout in seconds
LLM_TIMEOUT=60

# Number of retries on failure
LLM_MAX_RETRIES=3

# ------------------------------------------------
# Sentence Transformer Model
# ------------------------------------------------
# Model for generating embeddings
# Options: paraphrase-MiniLM-L6-v2 (fast), all-MiniLM-L12-v2 (better quality)
SENTENCE_TRANSFORMER_MODEL=paraphrase-MiniLM-L6-v2

# ------------------------------------------------
# Data Paths
# ------------------------------------------------
EMBEDDINGS_DIR=embeddings
DATA_DIR=data

# ------------------------------------------------
# Logging Configuration
# ------------------------------------------------
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
LOG_FILE=logs/echoes.log

# ------------------------------------------------
# Feature Flags
# ------------------------------------------------
# Use LLM for etymology generation
USE_LLM_ETYMOLOGY=true

# Cache LLM responses (improves performance for repeated queries)
CACHE_LLM_RESPONSES=true